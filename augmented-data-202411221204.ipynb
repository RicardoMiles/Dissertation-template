{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMBFwhaMNZ4qgzsCh9VdOuU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RicardoMiles/Dissertation-template/blob/main/augmented-data-202411221204.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIH7sVfQPiXH",
        "outputId": "0888a7b5-f8fd-411e-c079-18f15f70c024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks/SummerProject/src\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/SummerProject/src')\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 定义包含CSV文件的文件夹路径\n",
        "current_dir = os.getcwd()\n",
        "root_dir = os.path.dirname(current_dir)\n",
        "data_dir = os.path.join(root_dir, 'Data')\n",
        "left_data = os.path.join(data_dir,'left')\n",
        "right_data = os.path.join(data_dir,'right')\n",
        "\n",
        "folder_path = left_data\n",
        "\n",
        "# 获取left文件夹中所有CSV文件的列表\n",
        "csv_files_left = [os.path.join(left_data, file) for file in os.listdir(left_data) if file.endswith('.csv')]\n",
        "# 获取right文件夹中所有CSV文件的列表\n",
        "csv_files_right = [os.path.join(right_data, file) for file in os.listdir(right_data) if file.endswith('.csv')]\n",
        "\n",
        "print(f\"Number of left files: {len(csv_files_left)}\")\n",
        "print(f\"Number of right files: {len(csv_files_right)}\")"
      ],
      "metadata": {
        "id": "Em_TnpEVg30c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902dace9-7c75-4f0f-a4f5-0ff17a8b5b48"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of left files: 26\n",
            "Number of right files: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "# 定义特征提取函数\n",
        "def extract_features(group):\n",
        "    features = []\n",
        "    # 遍历第三列到最后一列\n",
        "    for col in group.columns[2:]:  # 从第三列开始提取特征\n",
        "        data = group[col].values\n",
        "        features.append(data.mean())  # 均值\n",
        "        features.append(data.std())   # 标准差\n",
        "        features.append(stats.skew(data))  # 偏度\n",
        "        features.append(stats.kurtosis(data))  # 峰度\n",
        "    return features"
      ],
      "metadata": {
        "id": "aJojEk5bh474"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372fe27a-5a39-4683-ca97-2996a6f859b0",
        "id": "ymVe5iOKXLIw"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total CSV files processed: 52\n"
          ]
        }
      ],
      "source": [
        "# 初始化存储所有特征和标签的列表\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "# 初始化CSV文件计数器\n",
        "csv_files_count = 0\n",
        "\n",
        "# 处理left文件夹中的CSV文件\n",
        "for file_name in csv_files_left:\n",
        "    df = pd.read_csv(file_name)\n",
        "    csv_files_count += 1  # 增加文件计数\n",
        "    # 将数据按照epoch分组\n",
        "    grouped = df.groupby(df.columns[1])  # 第二列是epoch分组的列\n",
        "    for name, group in grouped:\n",
        "        # 过滤掉time小于0的数据\n",
        "        group = group[group[df.columns[0]] >= 0]  # 假设time列是第一列\n",
        "        if len(group) == 81:  # 确保过滤后有81条数据\n",
        "        # if len(group) == 101:\n",
        "            # 提取特征\n",
        "            features = group.iloc[:, 2:].values  # 第三列及以后是EEG通道信号\n",
        "            all_features.append(features)\n",
        "            # 获取标签\n",
        "            all_labels.append('left')\n",
        "\n",
        "# 处理right文件夹中的CSV文件\n",
        "for file_name in csv_files_right:\n",
        "    df_right = pd.read_csv(file_name)\n",
        "    csv_files_count += 1  # 增加文件计数\n",
        "    # 将数据按照epoch分组\n",
        "    grouped_right = df_right.groupby(df_right.columns[1])  # 第二列是epoch分组的列\n",
        "    for name, group in grouped_right:\n",
        "        # 过滤掉time小于0的数据\n",
        "        group = group[group[df_right.columns[0]] >= 0]  # 假设time列是第一列\n",
        "        if len(group) == 81:  # 确保过滤后有81条数据\n",
        "        # if len(group) == 101:\n",
        "            # 提取特征\n",
        "            features = group.iloc[:, 2:].values  # 第三列及以后是EEG通道信号\n",
        "            all_features.append(features)\n",
        "            # 获取标签\n",
        "            all_labels.append('right')\n",
        "\n",
        "# 将特征和标签转换为NumPy数组\n",
        "features_array = np.array(all_features)\n",
        "labels_array = np.array(all_labels)\n",
        "\n",
        "# 打印处理的CSV文件数量\n",
        "print(f\"Total CSV files processed: {csv_files_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 定义衡量分布相似性的函数\n",
        "def evaluate_split_similarity(X_train, X_test):\n",
        "    train_mean = X_train.mean(axis=0)\n",
        "    test_mean = X_test.mean(axis=0)\n",
        "    # 使用均方差衡量分布差异\n",
        "    return np.mean((train_mean - test_mean) ** 2)\n",
        "\n",
        "best_seed = None\n",
        "min_difference = float('inf')\n",
        "\n",
        "for seed in range(100):  # 遍历多个种子\n",
        "    # 将 X 和 y 替换为 features_array 和 labels_array\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features_array, labels_array, test_size=0.2, random_state=seed)\n",
        "    diff = evaluate_split_similarity(X_train, X_test)\n",
        "    if diff < min_difference:\n",
        "        min_difference = diff\n",
        "        best_seed = seed\n",
        "\n",
        "print(f\"Best seed: {best_seed}, Minimum difference: {min_difference}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBPzcouMf8q0",
        "outputId": "73c7ac46-e642-4239-d742-b2a37c8d7c76"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best seed: 76, Minimum difference: 0.10239083541940588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total samples: {features_array.shape[0]}\")  # 样本数量\n",
        "print(f\"Timepoints per sample: {features_array.shape[1]}\")  # 每个样本的时间点\n",
        "print(f\"Features per timepoint: {features_array.shape[2]}\")  # 每个时间点的特征\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_gXZifRFhGv",
        "outputId": "83d372d5-dfb1-45a7-bdf8-8df2ac3e99d4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 7220\n",
            "Timepoints per sample: 81\n",
            "Features per timepoint: 101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(76)\n",
        "tf.random.set_seed(76)\n",
        "\n",
        "# 划分数据集\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_array, labels_array, test_size=0.2, random_state=42)\n",
        "\n",
        "# 打印当前处理的时间\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"Current processing time: {current_time}\")"
      ],
      "metadata": {
        "id": "gWYVXC1BiAfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "360cf9a3-f8d9-43b8-a49a-65f140a10bf8"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current processing time: 2024-11-22 11:00:06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Initial X_train shape: {X_train.shape}\")\n",
        "print(f\"Initial X_test shape: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zkkh3_bq9hr",
        "outputId": "6660dec1-d09b-49e2-9dc4-674b62302be3"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial X_train shape: (11552, 81, 101)\n",
            "Initial X_test shape: (1444, 81, 101)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 数据增强 (增加训练集的多样性)\n",
        "noise_factor = 0.1\n",
        "X_train_augmented = X_train + noise_factor * np.random.normal(size=X_train.shape)\n",
        "\n",
        "# 如果数据增强后想替代原训练集，可以直接覆盖：\n",
        "X_train = np.vstack((X_train, X_train_augmented))\n",
        "y_train = np.hstack((y_train, y_train))  # 扩展标签，假设数据增强不改变标签\n",
        "\n",
        "# 数据标准化\n",
        "# 获取数据的维度信息\n",
        "n_samples, n_timesteps, n_features = X_train.shape\n",
        "\n",
        "# 遍历每个特征进行标准化\n",
        "scalers = []  # 用于保存每个特征的标准化器\n",
        "for i in range(n_features):\n",
        "    scaler = StandardScaler()  # 为每个特征创建独立标准化器\n",
        "    # 对训练集的每个特征标准化\n",
        "    X_train[:, :, i] = scaler.fit_transform(X_train[:, :, i])\n",
        "    # 对测试集的每个特征标准化\n",
        "    X_test[:, :, i] = scaler.transform(X_test[:, :, i])\n",
        "    scalers.append(scaler)  # 保存该特征的标准化器\n",
        "\n",
        "    # 打印标准化后该特征的均值和标准差\n",
        "    print(f\"Feature {i} - Train mean: {X_train[:, :, i].mean():.5f}, Train std: {X_train[:, :, i].std():.5f}\")\n",
        "    print(f\"Feature {i} - Test mean: {X_test[:, :, i].mean():.5f}, Test std: {X_test[:, :, i].std():.5f}\")\n",
        "\n",
        "# 打印最终形状，确保没有改变\n",
        "print(f\"X_train shape after scaling: {X_train.shape}\")\n",
        "print(f\"X_test shape after scaling: {X_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2C3V8iRpX_k",
        "outputId": "27bdd059-8b0f-4386-b829-72f5a1424b2b"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 0 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 0 - Test mean: -0.01397, Test std: 1.01018\n",
            "Feature 1 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 1 - Test mean: -0.01167, Test std: 1.02506\n",
            "Feature 2 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 2 - Test mean: -0.00441, Test std: 1.01323\n",
            "Feature 3 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 3 - Test mean: -0.00876, Test std: 0.99427\n",
            "Feature 4 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 4 - Test mean: -0.01991, Test std: 0.98973\n",
            "Feature 5 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 5 - Test mean: -0.03362, Test std: 1.04537\n",
            "Feature 6 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 6 - Test mean: 0.01633, Test std: 1.01341\n",
            "Feature 7 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 7 - Test mean: -0.00246, Test std: 1.00679\n",
            "Feature 8 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 8 - Test mean: -0.03391, Test std: 0.97638\n",
            "Feature 9 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 9 - Test mean: -0.02768, Test std: 0.97796\n",
            "Feature 10 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 10 - Test mean: -0.04225, Test std: 0.94853\n",
            "Feature 11 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 11 - Test mean: -0.00725, Test std: 1.06528\n",
            "Feature 12 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 12 - Test mean: -0.01879, Test std: 1.02938\n",
            "Feature 13 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 13 - Test mean: -0.00394, Test std: 0.99296\n",
            "Feature 14 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 14 - Test mean: -0.03112, Test std: 0.97619\n",
            "Feature 15 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 15 - Test mean: -0.00051, Test std: 0.98846\n",
            "Feature 16 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 16 - Test mean: -0.03459, Test std: 1.08402\n",
            "Feature 17 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 17 - Test mean: -0.00880, Test std: 1.01937\n",
            "Feature 18 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 18 - Test mean: -0.02641, Test std: 1.04456\n",
            "Feature 19 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 19 - Test mean: 0.01163, Test std: 1.01703\n",
            "Feature 20 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 20 - Test mean: 0.00059, Test std: 1.00977\n",
            "Feature 21 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 21 - Test mean: -0.01255, Test std: 0.98080\n",
            "Feature 22 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 22 - Test mean: -0.01948, Test std: 0.98885\n",
            "Feature 23 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 23 - Test mean: -0.01845, Test std: 0.96991\n",
            "Feature 24 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 24 - Test mean: -0.04442, Test std: 1.00429\n",
            "Feature 25 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 25 - Test mean: 0.01193, Test std: 0.95788\n",
            "Feature 26 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 26 - Test mean: 0.00571, Test std: 1.00945\n",
            "Feature 27 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 27 - Test mean: 0.01340, Test std: 0.96570\n",
            "Feature 28 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 28 - Test mean: -0.00332, Test std: 0.99542\n",
            "Feature 29 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 29 - Test mean: -0.04162, Test std: 1.02736\n",
            "Feature 30 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 30 - Test mean: 0.01095, Test std: 0.98272\n",
            "Feature 31 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 31 - Test mean: -0.00233, Test std: 0.96203\n",
            "Feature 32 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 32 - Test mean: 0.00542, Test std: 0.98123\n",
            "Feature 33 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 33 - Test mean: -0.02281, Test std: 1.01138\n",
            "Feature 34 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 34 - Test mean: -0.01380, Test std: 0.95664\n",
            "Feature 35 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 35 - Test mean: 0.02323, Test std: 0.96252\n",
            "Feature 36 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 36 - Test mean: 0.02752, Test std: 0.96629\n",
            "Feature 37 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 37 - Test mean: 0.00512, Test std: 0.98846\n",
            "Feature 38 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 38 - Test mean: 0.02635, Test std: 0.88979\n",
            "Feature 39 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 39 - Test mean: 0.00904, Test std: 0.98113\n",
            "Feature 40 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 40 - Test mean: 0.00881, Test std: 1.17889\n",
            "Feature 41 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 41 - Test mean: 0.00157, Test std: 0.95019\n",
            "Feature 42 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 42 - Test mean: -0.02168, Test std: 0.87986\n",
            "Feature 43 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 43 - Test mean: -0.01163, Test std: 1.14217\n",
            "Feature 44 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 44 - Test mean: 0.02622, Test std: 1.20046\n",
            "Feature 45 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 45 - Test mean: 0.01925, Test std: 1.10832\n",
            "Feature 46 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 46 - Test mean: 0.02159, Test std: 0.96850\n",
            "Feature 47 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 47 - Test mean: -0.01053, Test std: 0.99100\n",
            "Feature 48 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 48 - Test mean: 0.00977, Test std: 0.96767\n",
            "Feature 49 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 49 - Test mean: 0.03746, Test std: 0.91572\n",
            "Feature 50 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 50 - Test mean: 0.03805, Test std: 1.03492\n",
            "Feature 51 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 51 - Test mean: 0.04508, Test std: 1.06923\n",
            "Feature 52 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 52 - Test mean: 0.02488, Test std: 0.98101\n",
            "Feature 53 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 53 - Test mean: 0.01004, Test std: 0.85780\n",
            "Feature 54 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 54 - Test mean: 0.01772, Test std: 1.03269\n",
            "Feature 55 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 55 - Test mean: 0.03661, Test std: 1.09543\n",
            "Feature 56 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 56 - Test mean: 0.05361, Test std: 1.04367\n",
            "Feature 57 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 57 - Test mean: 0.03861, Test std: 1.12285\n",
            "Feature 58 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 58 - Test mean: 0.03795, Test std: 1.25014\n",
            "Feature 59 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 59 - Test mean: 0.02858, Test std: 0.98509\n",
            "Feature 60 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 60 - Test mean: 0.01794, Test std: 0.99790\n",
            "Feature 61 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 61 - Test mean: 0.02408, Test std: 1.00832\n",
            "Feature 62 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 62 - Test mean: 0.01383, Test std: 0.97747\n",
            "Feature 63 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 63 - Test mean: 0.00892, Test std: 0.93745\n",
            "Feature 64 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 64 - Test mean: -0.01350, Test std: 0.95659\n",
            "Feature 65 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 65 - Test mean: 0.02651, Test std: 0.95844\n",
            "Feature 66 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 66 - Test mean: 0.03592, Test std: 1.02206\n",
            "Feature 67 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 67 - Test mean: 0.02829, Test std: 1.00780\n",
            "Feature 68 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 68 - Test mean: 0.02650, Test std: 0.97064\n",
            "Feature 69 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 69 - Test mean: -0.01004, Test std: 0.97224\n",
            "Feature 70 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 70 - Test mean: -0.02227, Test std: 1.04430\n",
            "Feature 71 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 71 - Test mean: 0.02143, Test std: 0.93857\n",
            "Feature 72 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 72 - Test mean: 0.03189, Test std: 1.00551\n",
            "Feature 73 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 73 - Test mean: 0.01151, Test std: 0.98856\n",
            "Feature 74 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 74 - Test mean: 0.02629, Test std: 0.84492\n",
            "Feature 75 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 75 - Test mean: 0.00076, Test std: 0.96661\n",
            "Feature 76 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 76 - Test mean: 0.01788, Test std: 1.16867\n",
            "Feature 77 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 77 - Test mean: 0.00796, Test std: 1.01174\n",
            "Feature 78 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 78 - Test mean: -0.00991, Test std: 0.97108\n",
            "Feature 79 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 79 - Test mean: -0.02723, Test std: 0.97379\n",
            "Feature 80 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 80 - Test mean: -0.00266, Test std: 0.95824\n",
            "Feature 81 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 81 - Test mean: -0.00773, Test std: 0.93041\n",
            "Feature 82 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 82 - Test mean: 0.00495, Test std: 0.98433\n",
            "Feature 83 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 83 - Test mean: -0.02121, Test std: 0.98011\n",
            "Feature 84 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 84 - Test mean: -0.00442, Test std: 0.97775\n",
            "Feature 85 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 85 - Test mean: -0.01776, Test std: 0.95060\n",
            "Feature 86 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 86 - Test mean: -0.02056, Test std: 1.20307\n",
            "Feature 87 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 87 - Test mean: 0.00848, Test std: 1.02022\n",
            "Feature 88 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 88 - Test mean: 0.00404, Test std: 1.02636\n",
            "Feature 89 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 89 - Test mean: -0.01185, Test std: 1.01043\n",
            "Feature 90 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 90 - Test mean: -0.02094, Test std: 1.00481\n",
            "Feature 91 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 91 - Test mean: 0.00731, Test std: 0.93473\n",
            "Feature 92 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 92 - Test mean: -0.01620, Test std: 0.94936\n",
            "Feature 93 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 93 - Test mean: -0.00090, Test std: 0.98763\n",
            "Feature 94 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 94 - Test mean: -0.00684, Test std: 0.96231\n",
            "Feature 95 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 95 - Test mean: -0.02308, Test std: 0.98400\n",
            "Feature 96 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 96 - Test mean: -0.02864, Test std: 1.07152\n",
            "Feature 97 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 97 - Test mean: -0.01725, Test std: 0.97617\n",
            "Feature 98 - Train mean: -0.00000, Train std: 1.00000\n",
            "Feature 98 - Test mean: -0.02003, Test std: 0.97655\n",
            "Feature 99 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 99 - Test mean: -0.02418, Test std: 1.07753\n",
            "Feature 100 - Train mean: 0.00000, Train std: 1.00000\n",
            "Feature 100 - Test mean: -0.04287, Test std: 0.99044\n",
            "X_train shape after scaling: (23104, 81, 101)\n",
            "X_test shape after scaling: (1444, 81, 101)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 初始化标签编码器\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# 将训练集和测试集的标签转换为数值\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# 确保转换后的标签是正确的数据类型\n",
        "y_train_encoded = y_train_encoded.astype('int32')\n",
        "y_test_encoded = y_test_encoded.astype('int32')"
      ],
      "metadata": {
        "id": "xU68yKwRiSCo"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_diff = np.abs(X_train.mean(axis=0) - X_test.mean(axis=0))\n",
        "std_diff = np.abs(X_train.std(axis=0) - X_test.std(axis=0))\n",
        "\n",
        "print(\"Mean differences:\", mean_diff)\n",
        "print(\"Standard deviation differences:\", std_diff)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0QFU4wojfeQ",
        "outputId": "1e837257-8028-4bae-98df-e755c83965bf"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean differences: [[3.37241854e-04 6.87156399e-03 1.79684577e-03 ... 1.41793396e-02\n",
            "  3.33282879e-02 6.08989240e-02]\n",
            " [6.64291291e-04 1.92440216e-02 1.18605785e-02 ... 2.60691529e-02\n",
            "  5.43354333e-02 6.79238397e-02]\n",
            " [1.19866106e-03 1.43251492e-02 8.93471500e-03 ... 2.58806970e-02\n",
            "  3.43823334e-02 6.28413570e-02]\n",
            " ...\n",
            " [6.51485050e-03 6.21707397e-03 1.44112486e-02 ... 2.82699617e-03\n",
            "  7.95581256e-05 6.23286344e-02]\n",
            " [8.48273665e-03 1.47875201e-02 2.04747564e-02 ... 9.91116080e-03\n",
            "  3.95445301e-03 5.93630617e-02]\n",
            " [5.03086636e-03 1.16587860e-02 2.05010026e-02 ... 6.47689070e-03\n",
            "  5.76516174e-03 5.41574191e-02]]\n",
            "Standard deviation differences: [[0.04518907 0.03333864 0.00735574 ... 0.03441924 0.08676005 0.02991205]\n",
            " [0.01854414 0.03550021 0.0026479  ... 0.01855029 0.14991921 0.03794212]\n",
            " [0.00494061 0.03906155 0.03295384 ... 0.01929248 0.16633659 0.04211394]\n",
            " ...\n",
            " [0.00684873 0.01066254 0.07231851 ... 0.05737158 0.01775333 0.03345705]\n",
            " [0.00805849 0.01147021 0.07786249 ... 0.05715694 0.02946487 0.04161241]\n",
            " [0.00775527 0.00699912 0.08036296 ... 0.05521283 0.03369043 0.05530986]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d4a16a1-75a0-47e0-afaf-70cef0579463",
        "id": "1JsdaAlyYuxr"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.5239 - loss: 0.6937 - val_accuracy: 0.5235 - val_loss: 0.6952\n",
            "Epoch 2/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5672 - loss: 0.6779 - val_accuracy: 0.5173 - val_loss: 0.7011\n",
            "Epoch 3/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5990 - loss: 0.6598 - val_accuracy: 0.5097 - val_loss: 0.7191\n",
            "Epoch 4/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6468 - loss: 0.6276 - val_accuracy: 0.5028 - val_loss: 0.7532\n",
            "Epoch 5/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6882 - loss: 0.5894 - val_accuracy: 0.5062 - val_loss: 0.8041\n",
            "Epoch 6/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.7340 - loss: 0.5399 - val_accuracy: 0.5173 - val_loss: 0.8582\n",
            "Epoch 7/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.7724 - loss: 0.4870 - val_accuracy: 0.5132 - val_loss: 0.9260\n",
            "Epoch 8/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8040 - loss: 0.4386 - val_accuracy: 0.5076 - val_loss: 1.0091\n",
            "Epoch 9/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8350 - loss: 0.3938 - val_accuracy: 0.5076 - val_loss: 1.1028\n",
            "Epoch 10/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8613 - loss: 0.3458 - val_accuracy: 0.5021 - val_loss: 1.1758\n",
            "Epoch 11/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8807 - loss: 0.3093 - val_accuracy: 0.4986 - val_loss: 1.2753\n",
            "Epoch 12/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8989 - loss: 0.2743 - val_accuracy: 0.5069 - val_loss: 1.3393\n",
            "Epoch 13/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9138 - loss: 0.2425 - val_accuracy: 0.5097 - val_loss: 1.4384\n",
            "Epoch 14/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9280 - loss: 0.2119 - val_accuracy: 0.5062 - val_loss: 1.5321\n",
            "Epoch 15/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9384 - loss: 0.1875 - val_accuracy: 0.5083 - val_loss: 1.6176\n",
            "Epoch 16/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9383 - loss: 0.1765 - val_accuracy: 0.5097 - val_loss: 1.7126\n",
            "Epoch 17/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9527 - loss: 0.1477 - val_accuracy: 0.5125 - val_loss: 1.7687\n",
            "Epoch 18/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9608 - loss: 0.1255 - val_accuracy: 0.5062 - val_loss: 1.9202\n",
            "Epoch 19/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9651 - loss: 0.1125 - val_accuracy: 0.5042 - val_loss: 1.9161\n",
            "Epoch 20/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9701 - loss: 0.1027 - val_accuracy: 0.5139 - val_loss: 2.0188\n",
            "Epoch 21/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9717 - loss: 0.0956 - val_accuracy: 0.5007 - val_loss: 2.1023\n",
            "Epoch 22/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9753 - loss: 0.0839 - val_accuracy: 0.4986 - val_loss: 2.1544\n",
            "Epoch 23/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9776 - loss: 0.0797 - val_accuracy: 0.5090 - val_loss: 2.2030\n",
            "Epoch 24/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9836 - loss: 0.0645 - val_accuracy: 0.5055 - val_loss: 2.3255\n",
            "Epoch 25/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9786 - loss: 0.0737 - val_accuracy: 0.5076 - val_loss: 2.2958\n",
            "Epoch 26/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9833 - loss: 0.0615 - val_accuracy: 0.5083 - val_loss: 2.3997\n",
            "Epoch 27/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9869 - loss: 0.0545 - val_accuracy: 0.4979 - val_loss: 2.4730\n",
            "Epoch 28/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9891 - loss: 0.0460 - val_accuracy: 0.5035 - val_loss: 2.5125\n",
            "Epoch 29/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9867 - loss: 0.0508 - val_accuracy: 0.5062 - val_loss: 2.5550\n",
            "Epoch 30/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9867 - loss: 0.0472 - val_accuracy: 0.4986 - val_loss: 2.5521\n",
            "Epoch 31/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.0392 - val_accuracy: 0.5048 - val_loss: 2.6444\n",
            "Epoch 32/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9900 - loss: 0.0392 - val_accuracy: 0.5069 - val_loss: 2.6417\n",
            "Epoch 33/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0436 - val_accuracy: 0.5090 - val_loss: 2.6364\n",
            "Epoch 34/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0322 - val_accuracy: 0.5104 - val_loss: 2.6963\n",
            "Epoch 35/35\n",
            "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9890 - loss: 0.0394 - val_accuracy: 0.5090 - val_loss: 2.8324\n",
            "Test Loss: 2.832411050796509\n",
            "Test Accuracy: 0.5090027451515198\n",
            "Current processing time: 2024-11-22 11:45:48\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, InputLayer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 假设 X_train, X_test, y_train, y_test 已经定义并准备好了\n",
        "# 构建LSTM模型\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(Dropout(0.3))  # 添加Dropout层\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dropout(0.3))  # 添加Dropout层\n",
        "model.add(Dense(1, activation='sigmoid'))  # 二分类问题\n",
        "\n",
        "# 编译模型\n",
        "model.compile(Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 早停法\n",
        "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
        "\n",
        "# 训练模型\n",
        "model.fit(X_train, y_train_encoded, epochs=35, batch_size=32, validation_data=(X_test, y_test_encoded))\n",
        "\n",
        "# 评估模型\n",
        "loss, accuracy = model.evaluate(X_test, y_test_encoded, verbose=0)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "# 打印当前处理的时间\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"Current processing time: {current_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 预测测试集\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# 将概率转换为类别\n",
        "predicted_classes = (predictions > 0.5).astype(\"int32\")\n",
        "\n",
        "# 打印预测结果\n",
        "print(predicted_classes)\n",
        "\n",
        "# 打印当前处理的时间\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"Current processing time: {current_time}\")"
      ],
      "metadata": {
        "id": "2db_B0Cbkqe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "112cd42e-5ed2-4e91-e639-ce353cccf44f"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "[[0]\n",
            " [1]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [1]]\n",
            "Current processing time: 2024-11-22 11:45:56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算精确度、召回率和F1分数\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "precision = precision_score(y_test_encoded, predicted_classes)\n",
        "recall = recall_score(y_test_encoded, predicted_classes)\n",
        "f1 = f1_score(y_test_encoded, predicted_classes)\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "# 计算混淆矩阵\n",
        "cm = confusion_matrix(y_test_encoded, predicted_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# 打印当前处理的时间\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"Current processing time: {current_time}\")"
      ],
      "metadata": {
        "id": "7scZd9fxkrbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab5c40aa-fe6f-41df-8abb-cc6a8768b12f"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.4962852897473997\n",
            "Recall: 0.4744318181818182\n",
            "F1 Score: 0.4851125635439361\n",
            "Confusion Matrix:\n",
            "[[401 339]\n",
            " [370 334]]\n",
            "Current processing time: 2024-11-22 11:45:59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RLrwu2iFkuZE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}