{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPlnBCN+V9YqAsZomx6/A50",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RicardoMiles/Dissertation-template/blob/main/RandomSearch-parameter-202411221955.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIH7sVfQPiXH",
        "outputId": "9f7849c7-a10d-45d6-db60-ed5dc30c993c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks/SummerProject/src\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/SummerProject/src')\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 定义包含CSV文件的文件夹路径\n",
        "current_dir = os.getcwd()\n",
        "root_dir = os.path.dirname(current_dir)\n",
        "data_dir = os.path.join(root_dir, 'Data')\n",
        "left_data = os.path.join(data_dir,'left')\n",
        "right_data = os.path.join(data_dir,'right')\n",
        "\n",
        "folder_path = left_data\n",
        "\n",
        "# 获取left文件夹中所有CSV文件的列表\n",
        "csv_files_left = [os.path.join(left_data, file) for file in os.listdir(left_data) if file.endswith('.csv')]\n",
        "# 获取right文件夹中所有CSV文件的列表\n",
        "csv_files_right = [os.path.join(right_data, file) for file in os.listdir(right_data) if file.endswith('.csv')]\n",
        "\n",
        "print(f\"Number of left files: {len(csv_files_left)}\")\n",
        "print(f\"Number of right files: {len(csv_files_right)}\")"
      ],
      "metadata": {
        "id": "Em_TnpEVg30c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "351b1e27-db6e-4c34-948b-8e5eb762393a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of left files: 26\n",
            "Number of right files: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "# 定义特征提取函数\n",
        "def extract_features(group):\n",
        "    features = []\n",
        "    # 遍历第三列到最后一列\n",
        "    for col in group.columns[2:]:  # 从第三列开始提取特征\n",
        "        data = group[col].values\n",
        "        features.append(data.mean())  # 均值\n",
        "        features.append(data.std())   # 标准差\n",
        "        features.append(stats.skew(data))  # 偏度\n",
        "        features.append(stats.kurtosis(data))  # 峰度\n",
        "    return features"
      ],
      "metadata": {
        "id": "aJojEk5bh474"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37dc1d66-ebb5-4823-bcfc-65ba23a3418c",
        "id": "ymVe5iOKXLIw"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total CSV files processed: 52\n"
          ]
        }
      ],
      "source": [
        "# 初始化存储所有特征和标签的列表\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "# 初始化CSV文件计数器\n",
        "csv_files_count = 0\n",
        "\n",
        "# 处理left文件夹中的CSV文件\n",
        "for file_name in csv_files_left:\n",
        "    df = pd.read_csv(file_name)\n",
        "    csv_files_count += 1  # 增加文件计数\n",
        "    # 将数据按照epoch分组\n",
        "    grouped = df.groupby(df.columns[1])  # 第二列是epoch分组的列\n",
        "    for name, group in grouped:\n",
        "        # 过滤掉time小于0的数据\n",
        "        group = group[group[df.columns[0]] >= 0]  # 假设time列是第一列\n",
        "        if len(group) == 81:  # 确保过滤后有81条数据\n",
        "        # if len(group) == 101:\n",
        "            # 提取特征\n",
        "            features = group.iloc[:, 2:].values  # 第三列及以后是EEG通道信号\n",
        "            all_features.append(features)\n",
        "            # 获取标签\n",
        "            all_labels.append('left')\n",
        "\n",
        "# 处理right文件夹中的CSV文件\n",
        "for file_name in csv_files_right:\n",
        "    df_right = pd.read_csv(file_name)\n",
        "    csv_files_count += 1  # 增加文件计数\n",
        "    # 将数据按照epoch分组\n",
        "    grouped_right = df_right.groupby(df_right.columns[1])  # 第二列是epoch分组的列\n",
        "    for name, group in grouped_right:\n",
        "        # 过滤掉time小于0的数据\n",
        "        group = group[group[df_right.columns[0]] >= 0]  # 假设time列是第一列\n",
        "        if len(group) == 81:  # 确保过滤后有81条数据\n",
        "        # if len(group) == 101:\n",
        "            # 提取特征\n",
        "            features = group.iloc[:, 2:].values  # 第三列及以后是EEG通道信号\n",
        "            all_features.append(features)\n",
        "            # 获取标签\n",
        "            all_labels.append('right')\n",
        "\n",
        "# 将特征和标签转换为NumPy数组\n",
        "features_array = np.array(all_features)\n",
        "labels_array = np.array(all_labels)\n",
        "\n",
        "# 打印处理的CSV文件数量\n",
        "print(f\"Total CSV files processed: {csv_files_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 定义衡量分布相似性的函数\n",
        "def evaluate_split_similarity(X_train, X_test):\n",
        "    train_mean = X_train.mean(axis=0)\n",
        "    test_mean = X_test.mean(axis=0)\n",
        "    # 使用均方差衡量分布差异\n",
        "    return np.mean((train_mean - test_mean) ** 2)\n",
        "\n",
        "best_seed = None\n",
        "min_difference = float('inf')\n",
        "\n",
        "for seed in range(100):  # 遍历多个种子\n",
        "    # 将 X 和 y 替换为 features_array 和 labels_array\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features_array, labels_array, test_size=0.2, random_state=seed)\n",
        "    diff = evaluate_split_similarity(X_train, X_test)\n",
        "    if diff < min_difference:\n",
        "        min_difference = diff\n",
        "        best_seed = seed\n",
        "\n",
        "print(f\"Best seed: {best_seed}, Minimum difference: {min_difference}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBPzcouMf8q0",
        "outputId": "2f522c8f-655c-4a22-9e5b-8baee923ea97"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best seed: 76, Minimum difference: 0.10239083541940588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total samples: {features_array.shape[0]}\")  # 样本数量\n",
        "print(f\"Timepoints per sample: {features_array.shape[1]}\")  # 每个样本的时间点\n",
        "print(f\"Features per timepoint: {features_array.shape[2]}\")  # 每个时间点的特征\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_gXZifRFhGv",
        "outputId": "8d0eadd6-ccf6-4723-cd34-da5b494cf2cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 7220\n",
            "Timepoints per sample: 81\n",
            "Features per timepoint: 101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(76)\n",
        "tf.random.set_seed(76)\n",
        "\n",
        "# 划分数据集\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_array, labels_array, test_size=0.2, random_state=42)\n",
        "\n",
        "# 打印当前处理的时间\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"Current processing time: {current_time}\")"
      ],
      "metadata": {
        "id": "gWYVXC1BiAfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2bc56be-a0b2-4643-94f1-a29619838ddd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current processing time: 2024-11-22 17:47:54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Initial X_train shape: {X_train.shape}\")\n",
        "print(f\"Initial X_test shape: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zkkh3_bq9hr",
        "outputId": "3f70d1e3-fc1b-4f6e-d644-59a79793d4ab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial X_train shape: (5776, 81, 101)\n",
            "Initial X_test shape: (1444, 81, 101)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 初始化标签编码器\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# 将训练集和测试集的标签转换为数值\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# 确保转换后的标签是正确的数据类型\n",
        "y_train_encoded = y_train_encoded.astype('int32')\n",
        "y_test_encoded = y_test_encoded.astype('int32')"
      ],
      "metadata": {
        "id": "xU68yKwRiSCo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, InputLayer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "!pip install keras-tuner\n",
        "import keras_tuner as kt\n",
        "from datetime import datetime\n",
        "\n",
        "# 假设 X_train, X_test, y_train, y_test 已经定义并准备好了\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "    # LSTM layers\n",
        "    for i in range(hp.Int('lstm_layers', 1, 3)):\n",
        "        model.add(LSTM(units=hp.Int('units_' + str(i), min_value=10, max_value=100, step=10),\n",
        "                       return_sequences=i < hp.Int('lstm_layers', 1, 3) - 1))\n",
        "        model.add(Dropout(hp.Float('dropout_' + str(i), min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))  # 二分类问题\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=100,  # 你可以根据需要调整试验次数\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='intro_to_kt'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train_encoded, epochs=35, batch_size=32, validation_data=(X_test, y_test_encoded))\n",
        "\n",
        "# 获取最佳模型\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# 评估模型\n",
        "loss, accuracy = best_model.evaluate(X_test, y_test_encoded, verbose=0)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "# 打印当前处理的时间\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"Current processing time: {current_time}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnxpndOs_oUO",
        "outputId": "f9aa89a4-1b4d-4e2f-f016-58466eb85c17"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 100 Complete [00h 01m 31s]\n",
            "val_accuracy: 0.5491690039634705\n",
            "\n",
            "Best val_accuracy So Far: 0.5706371068954468\n",
            "Total elapsed time: 01h 52m 45s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.6870168447494507\n",
            "Test Accuracy: 0.5706371068954468\n",
            "Current processing time: 2024-11-22 19:43:59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3075185-cb7e-4c9b-e204-88fc270816c5",
        "id": "1JsdaAlyYuxr"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.4955 - loss: 0.7119 - val_accuracy: 0.5014 - val_loss: 0.6976\n",
            "Epoch 2/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5053 - loss: 0.7061 - val_accuracy: 0.5145 - val_loss: 0.6951\n",
            "Epoch 3/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5293 - loss: 0.6951 - val_accuracy: 0.5145 - val_loss: 0.6941\n",
            "Epoch 4/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5272 - loss: 0.6922 - val_accuracy: 0.5173 - val_loss: 0.6938\n",
            "Epoch 5/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5365 - loss: 0.6899 - val_accuracy: 0.5132 - val_loss: 0.6934\n",
            "Epoch 6/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5373 - loss: 0.6912 - val_accuracy: 0.5145 - val_loss: 0.6927\n",
            "Epoch 7/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5296 - loss: 0.6910 - val_accuracy: 0.5215 - val_loss: 0.6926\n",
            "Epoch 8/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5463 - loss: 0.6864 - val_accuracy: 0.5180 - val_loss: 0.6924\n",
            "Epoch 9/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5562 - loss: 0.6840 - val_accuracy: 0.5249 - val_loss: 0.6930\n",
            "Epoch 10/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5613 - loss: 0.6823 - val_accuracy: 0.5159 - val_loss: 0.6927\n",
            "Epoch 11/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5608 - loss: 0.6807 - val_accuracy: 0.5132 - val_loss: 0.6932\n",
            "Epoch 12/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5539 - loss: 0.6820 - val_accuracy: 0.5139 - val_loss: 0.6934\n",
            "Epoch 13/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5683 - loss: 0.6757 - val_accuracy: 0.5187 - val_loss: 0.6934\n",
            "Epoch 14/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5957 - loss: 0.6698 - val_accuracy: 0.5208 - val_loss: 0.6948\n",
            "Epoch 15/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5909 - loss: 0.6693 - val_accuracy: 0.5235 - val_loss: 0.6954\n",
            "Epoch 16/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5916 - loss: 0.6674 - val_accuracy: 0.5187 - val_loss: 0.6968\n",
            "Epoch 17/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5995 - loss: 0.6662 - val_accuracy: 0.5208 - val_loss: 0.6987\n",
            "Epoch 18/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5933 - loss: 0.6647 - val_accuracy: 0.5256 - val_loss: 0.7009\n",
            "Epoch 19/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6033 - loss: 0.6606 - val_accuracy: 0.5298 - val_loss: 0.7029\n",
            "Epoch 20/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6013 - loss: 0.6606 - val_accuracy: 0.5298 - val_loss: 0.7068\n",
            "Epoch 21/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6191 - loss: 0.6524 - val_accuracy: 0.5201 - val_loss: 0.7095\n",
            "Epoch 22/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6206 - loss: 0.6504 - val_accuracy: 0.5166 - val_loss: 0.7122\n",
            "Epoch 23/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6352 - loss: 0.6394 - val_accuracy: 0.5152 - val_loss: 0.7193\n",
            "Epoch 24/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6453 - loss: 0.6375 - val_accuracy: 0.5118 - val_loss: 0.7247\n",
            "Epoch 25/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6439 - loss: 0.6354 - val_accuracy: 0.5007 - val_loss: 0.7321\n",
            "Epoch 26/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6398 - loss: 0.6337 - val_accuracy: 0.5035 - val_loss: 0.7381\n",
            "Epoch 27/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6554 - loss: 0.6217 - val_accuracy: 0.5048 - val_loss: 0.7434\n",
            "Epoch 28/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6548 - loss: 0.6151 - val_accuracy: 0.5028 - val_loss: 0.7513\n",
            "Epoch 29/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6669 - loss: 0.6115 - val_accuracy: 0.5007 - val_loss: 0.7583\n",
            "Epoch 30/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6724 - loss: 0.6083 - val_accuracy: 0.4910 - val_loss: 0.7675\n",
            "Epoch 31/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6845 - loss: 0.5987 - val_accuracy: 0.5000 - val_loss: 0.7729\n",
            "Epoch 32/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6848 - loss: 0.5957 - val_accuracy: 0.5021 - val_loss: 0.7765\n",
            "Epoch 33/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6881 - loss: 0.5880 - val_accuracy: 0.5062 - val_loss: 0.7869\n",
            "Epoch 34/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6978 - loss: 0.5809 - val_accuracy: 0.4979 - val_loss: 0.7979\n",
            "Epoch 35/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7164 - loss: 0.5670 - val_accuracy: 0.5048 - val_loss: 0.8054\n",
            "Test Loss: 0.8054308295249939\n",
            "Test Accuracy: 0.5048476457595825\n",
            "Current processing time: 2024-11-22 17:49:17\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, InputLayer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 假设 X_train, X_test, y_train, y_test 已经定义并准备好了\n",
        "# 构建LSTM模型\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(LSTM(units=30, return_sequences=True))\n",
        "model.add(Dropout(0.4))  # 添加Dropout层\n",
        "model.add(LSTM(units=30))\n",
        "model.add(Dropout(0.4))  # 添加Dropout层\n",
        "model.add(Dense(1, activation='sigmoid'))  # 二分类问题\n",
        "\n",
        "# 编译模型\n",
        "model.compile(Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 早停法\n",
        "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
        "\n",
        "# 训练模型\n",
        "model.fit(X_train, y_train_encoded, epochs=35, batch_size=32, validation_data=(X_test, y_test_encoded))\n",
        "\n",
        "# 评估模型\n",
        "loss, accuracy = model.evaluate(X_test, y_test_encoded, verbose=0)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "# 打印当前处理的时间\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"Current processing time: {current_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = tuner.get_best_hyperparameters()[0]\n",
        "for key, value in best_hps.values.items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CF0PMfIaegs",
        "outputId": "c5988734-607c-4777-aa7b-20f29d68a986"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lstm_layers: 2\n",
            "units_0: 30\n",
            "dropout_0: 0.5\n",
            "learning_rate: 0.005283071526371937\n",
            "units_1: 80\n",
            "dropout_1: 0.1\n",
            "units_2: 10\n",
            "dropout_2: 0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 预测测试集\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# 将概率转换为类别\n",
        "predicted_classes = (predictions > 0.5).astype(\"int32\")\n",
        "\n",
        "# 打印预测结果\n",
        "print(predicted_classes)\n",
        "\n",
        "# 打印当前处理的时间\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"Current processing time: {current_time}\")"
      ],
      "metadata": {
        "id": "2db_B0Cbkqe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b3794b-513f-4536-fc09-e6da34fbf51c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "[[1]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n",
            "Current processing time: 2024-11-22 19:55:03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算精确度、召回率和F1分数\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "precision = precision_score(y_test_encoded, predicted_classes)\n",
        "recall = recall_score(y_test_encoded, predicted_classes)\n",
        "f1 = f1_score(y_test_encoded, predicted_classes)\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "# 计算混淆矩阵\n",
        "cm = confusion_matrix(y_test_encoded, predicted_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# 打印当前处理的时间\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"Current processing time: {current_time}\")"
      ],
      "metadata": {
        "id": "7scZd9fxkrbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7b30af-fe32-4f14-d5c3-4e67b8ebcd3c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.48625180897250364\n",
            "Recall: 0.4827586206896552\n",
            "F1 Score: 0.4844989185291997\n",
            "Confusion Matrix:\n",
            "[[393 355]\n",
            " [360 336]]\n",
            "Current processing time: 2024-11-22 19:55:05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RLrwu2iFkuZE"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}