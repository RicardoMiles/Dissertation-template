{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOGTbL+0VS8kAMRI1TCcI6N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RicardoMiles/Dissertation-template/blob/main/Raw-data-feature-with-RFanalysis-202411221011.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIH7sVfQPiXH",
        "outputId": "0888a7b5-f8fd-411e-c079-18f15f70c024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks/SummerProject/src\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/SummerProject/src')\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 定义包含CSV文件的文件夹路径\n",
        "current_dir = os.getcwd()\n",
        "root_dir = os.path.dirname(current_dir)\n",
        "data_dir = os.path.join(root_dir, 'Data')\n",
        "left_data = os.path.join(data_dir,'left')\n",
        "right_data = os.path.join(data_dir,'right')\n",
        "\n",
        "folder_path = left_data\n",
        "\n",
        "# 获取left文件夹中所有CSV文件的列表\n",
        "csv_files_left = [os.path.join(left_data, file) for file in os.listdir(left_data) if file.endswith('.csv')]\n",
        "# 获取right文件夹中所有CSV文件的列表\n",
        "csv_files_right = [os.path.join(right_data, file) for file in os.listdir(right_data) if file.endswith('.csv')]\n",
        "\n",
        "print(f\"Number of left files: {len(csv_files_left)}\")\n",
        "print(f\"Number of right files: {len(csv_files_right)}\")"
      ],
      "metadata": {
        "id": "Em_TnpEVg30c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902dace9-7c75-4f0f-a4f5-0ff17a8b5b48"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of left files: 26\n",
            "Number of right files: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "# 定义特征提取函数\n",
        "def extract_features(group):\n",
        "    features = []\n",
        "    # 遍历第三列到最后一列\n",
        "    for col in group.columns[2:]:  # 从第三列开始提取特征\n",
        "        data = group[col].values\n",
        "        features.append(data.mean())  # 均值\n",
        "        features.append(data.std())   # 标准差\n",
        "        features.append(stats.skew(data))  # 偏度\n",
        "        features.append(stats.kurtosis(data))  # 峰度\n",
        "    return features"
      ],
      "metadata": {
        "id": "aJojEk5bh474"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da6a3377-aa16-43ef-e882-1fa6aa4c1b3d",
        "id": "ymVe5iOKXLIw"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total CSV files processed: 52\n"
          ]
        }
      ],
      "source": [
        "# 初始化存储所有特征和标签的列表\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "# 初始化CSV文件计数器\n",
        "csv_files_count = 0\n",
        "\n",
        "# 处理left文件夹中的CSV文件\n",
        "for file_name in csv_files_left:\n",
        "    df = pd.read_csv(file_name)\n",
        "    csv_files_count += 1  # 增加文件计数\n",
        "    # 将数据按照epoch分组\n",
        "    grouped = df.groupby(df.columns[1])  # 第二列是epoch分组的列\n",
        "    for name, group in grouped:\n",
        "        # 过滤掉time小于0的数据\n",
        "        # group = group[group[df.columns[0]] >= 0]  # 假设time列是第一列\n",
        "        # if len(group) == 81:  # 确保过滤后有81条数据\n",
        "        if len(group) == 101:\n",
        "            # 提取特征\n",
        "            features = group.iloc[:, 2:].values  # 第三列及以后是EEG通道信号\n",
        "            all_features.append(features)\n",
        "            # 获取标签\n",
        "            all_labels.append('left')\n",
        "\n",
        "# 处理right文件夹中的CSV文件\n",
        "for file_name in csv_files_right:\n",
        "    df_right = pd.read_csv(file_name)\n",
        "    csv_files_count += 1  # 增加文件计数\n",
        "    # 将数据按照epoch分组\n",
        "    grouped_right = df_right.groupby(df_right.columns[1])  # 第二列是epoch分组的列\n",
        "    for name, group in grouped_right:\n",
        "        # 过滤掉time小于0的数据\n",
        "        # group = group[group[df_right.columns[0]] >= 0]  # 假设time列是第一列\n",
        "        # if len(group) == 81:  # 确保过滤后有81条数据\n",
        "        if len(group) == 101:\n",
        "            # 提取特征\n",
        "            features = group.iloc[:, 2:].values  # 第三列及以后是EEG通道信号\n",
        "            all_features.append(features)\n",
        "            # 获取标签\n",
        "            all_labels.append('right')\n",
        "\n",
        "# 将特征和标签转换为NumPy数组\n",
        "features_array = np.array(all_features)\n",
        "labels_array = np.array(all_labels)\n",
        "\n",
        "# 打印处理的CSV文件数量\n",
        "print(f\"Total CSV files processed: {csv_files_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total samples: {features_array.shape[0]}\")  # 样本数量\n",
        "print(f\"Timepoints per sample: {features_array.shape[1]}\")  # 每个样本的时间点\n",
        "print(f\"Features per timepoint: {features_array.shape[2]}\")  # 每个时间点的特征\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_gXZifRFhGv",
        "outputId": "e07c0447-ae61-41d8-feca-60cde36d5f2b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 7220\n",
            "Timepoints per sample: 101\n",
            "Features per timepoint: 101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# 划分数据集\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_array, labels_array, test_size=0.2, random_state=42)\n",
        "\n",
        "# 打印当前处理的时间\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"Current processing time: {current_time}\")"
      ],
      "metadata": {
        "id": "gWYVXC1BiAfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dad56df-426e-46c0-bdc5-b63c3af2c125"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current processing time: 2024-11-22 10:05:01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 初始化标签编码器\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# 将训练集和测试集的标签转换为数值\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# 确保转换后的标签是正确的数据类型\n",
        "y_train_encoded = y_train_encoded.astype('int32')\n",
        "y_test_encoded = y_test_encoded.astype('int32')"
      ],
      "metadata": {
        "id": "xU68yKwRiSCo"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 展平数据，适配随机森林\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# 训练随机森林\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train_flat, y_train)\n",
        "\n",
        "# 预测并评估\n",
        "y_pred = clf.predict(X_test_flat)\n",
        "print(f\"Random Forest Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH58KCFVQrXp",
        "outputId": "e49e83b9-2c96-4830-8218-03870a35eafb"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.5436288088642659\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        left       0.55      0.62      0.58       748\n",
            "       right       0.53      0.46      0.49       696\n",
            "\n",
            "    accuracy                           0.54      1444\n",
            "   macro avg       0.54      0.54      0.54      1444\n",
            "weighted avg       0.54      0.54      0.54      1444\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9fed131-0fa5-44dd-f8ff-6d5985b84adb",
        "id": "1JsdaAlyYuxr"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5031 - loss: 0.7031 - val_accuracy: 0.5097 - val_loss: 0.6947\n",
            "Epoch 2/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5473 - loss: 0.6878 - val_accuracy: 0.5132 - val_loss: 0.6936\n",
            "Epoch 3/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5734 - loss: 0.6765 - val_accuracy: 0.5263 - val_loss: 0.6943\n",
            "Epoch 4/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5864 - loss: 0.6699 - val_accuracy: 0.5145 - val_loss: 0.7118\n",
            "Epoch 5/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5938 - loss: 0.6627 - val_accuracy: 0.5208 - val_loss: 0.7031\n",
            "Epoch 6/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6265 - loss: 0.6445 - val_accuracy: 0.5409 - val_loss: 0.7114\n",
            "Epoch 7/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6481 - loss: 0.6286 - val_accuracy: 0.5159 - val_loss: 0.7455\n",
            "Epoch 8/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6676 - loss: 0.6088 - val_accuracy: 0.5229 - val_loss: 0.7277\n",
            "Epoch 9/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6706 - loss: 0.5991 - val_accuracy: 0.5235 - val_loss: 0.7623\n",
            "Epoch 10/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6735 - loss: 0.5823 - val_accuracy: 0.5492 - val_loss: 0.7493\n",
            "Epoch 11/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6999 - loss: 0.5554 - val_accuracy: 0.5235 - val_loss: 0.7562\n",
            "Epoch 12/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7247 - loss: 0.5333 - val_accuracy: 0.5173 - val_loss: 0.8462\n",
            "Epoch 13/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7349 - loss: 0.5226 - val_accuracy: 0.5284 - val_loss: 0.8762\n",
            "Epoch 14/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7546 - loss: 0.4951 - val_accuracy: 0.5325 - val_loss: 0.8371\n",
            "Epoch 15/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7644 - loss: 0.4768 - val_accuracy: 0.5325 - val_loss: 0.8396\n",
            "Epoch 16/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7718 - loss: 0.4663 - val_accuracy: 0.5145 - val_loss: 0.9188\n",
            "Epoch 17/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7918 - loss: 0.4345 - val_accuracy: 0.5166 - val_loss: 0.9447\n",
            "Epoch 18/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7942 - loss: 0.4308 - val_accuracy: 0.5152 - val_loss: 0.9075\n",
            "Epoch 19/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8022 - loss: 0.4161 - val_accuracy: 0.5187 - val_loss: 0.9842\n",
            "Epoch 20/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7941 - loss: 0.4124 - val_accuracy: 0.5402 - val_loss: 0.9437\n",
            "Epoch 21/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8147 - loss: 0.3867 - val_accuracy: 0.5319 - val_loss: 1.0354\n",
            "Epoch 22/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8285 - loss: 0.3662 - val_accuracy: 0.5409 - val_loss: 1.0840\n",
            "Epoch 23/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8414 - loss: 0.3488 - val_accuracy: 0.5242 - val_loss: 1.1717\n",
            "Epoch 24/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8209 - loss: 0.3680 - val_accuracy: 0.5402 - val_loss: 1.1160\n",
            "Epoch 25/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8533 - loss: 0.3262 - val_accuracy: 0.5256 - val_loss: 1.1679\n",
            "Epoch 26/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8471 - loss: 0.3313 - val_accuracy: 0.5242 - val_loss: 1.1999\n",
            "Epoch 27/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8611 - loss: 0.3037 - val_accuracy: 0.5139 - val_loss: 1.2500\n",
            "Epoch 28/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8669 - loss: 0.2941 - val_accuracy: 0.5208 - val_loss: 1.2926\n",
            "Epoch 29/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8588 - loss: 0.2894 - val_accuracy: 0.5263 - val_loss: 1.3130\n",
            "Epoch 30/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8667 - loss: 0.2996 - val_accuracy: 0.5229 - val_loss: 1.2466\n",
            "Epoch 31/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8710 - loss: 0.2805 - val_accuracy: 0.5208 - val_loss: 1.4055\n",
            "Epoch 32/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8743 - loss: 0.2936 - val_accuracy: 0.5173 - val_loss: 1.3111\n",
            "Epoch 33/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8752 - loss: 0.2696 - val_accuracy: 0.5104 - val_loss: 1.5219\n",
            "Epoch 34/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8958 - loss: 0.2586 - val_accuracy: 0.5152 - val_loss: 1.3932\n",
            "Epoch 35/35\n",
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8936 - loss: 0.2384 - val_accuracy: 0.5104 - val_loss: 1.4365\n",
            "Test Loss: 1.4365383386611938\n",
            "Test Accuracy: 0.5103878378868103\n",
            "Current processing time: 2024-11-22 10:10:41\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, InputLayer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 假设 X_train, X_test, y_train, y_test 已经定义并准备好了\n",
        "# 构建LSTM模型\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(Dropout(0.3))  # 添加Dropout层\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dropout(0.3))  # 添加Dropout层\n",
        "model.add(Dense(1, activation='sigmoid'))  # 二分类问题\n",
        "\n",
        "# 编译模型\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 早停法\n",
        "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
        "\n",
        "# 训练模型\n",
        "model.fit(X_train, y_train_encoded, epochs=35, batch_size=32, validation_data=(X_test, y_test_encoded))\n",
        "\n",
        "# 评估模型\n",
        "loss, accuracy = model.evaluate(X_test, y_test_encoded, verbose=0)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "# 打印当前处理的时间\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"Current processing time: {current_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 预测测试集\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# 将概率转换为类别\n",
        "predicted_classes = (predictions > 0.5).astype(\"int32\")\n",
        "\n",
        "# 打印预测结果\n",
        "print(predicted_classes)\n",
        "\n",
        "# 打印当前处理的时间\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"Current processing time: {current_time}\")"
      ],
      "metadata": {
        "id": "2db_B0Cbkqe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87fd0852-a225-4ab6-da9c-4c776a1ccf19"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "[[0]\n",
            " [1]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [1]\n",
            " [1]]\n",
            "Current processing time: 2024-11-22 10:10:52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算精确度、召回率和F1分数\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "precision = precision_score(y_test_encoded, predicted_classes)\n",
        "recall = recall_score(y_test_encoded, predicted_classes)\n",
        "f1 = f1_score(y_test_encoded, predicted_classes)\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "# 计算混淆矩阵\n",
        "cm = confusion_matrix(y_test_encoded, predicted_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# 打印当前处理的时间\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"Current processing time: {current_time}\")"
      ],
      "metadata": {
        "id": "7scZd9fxkrbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50095575-e82d-43cf-b00c-9953cb559905"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.4922425952045134\n",
            "Recall: 0.5014367816091954\n",
            "F1 Score: 0.496797153024911\n",
            "Confusion Matrix:\n",
            "[[388 360]\n",
            " [347 349]]\n",
            "Current processing time: 2024-11-22 10:10:56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RLrwu2iFkuZE"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}